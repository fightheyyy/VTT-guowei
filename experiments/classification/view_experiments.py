"""
æŸ¥çœ‹å®éªŒç»“æœçš„ä¾¿æ·è„šæœ¬
"""

import sys
sys.path.append('../..')

import pandas as pd
import argparse
from experiment_tracker import ExperimentTracker
from pathlib import Path


def show_summary():
    """æ˜¾ç¤ºå®éªŒæ‘˜è¦"""
    tracker = ExperimentTracker()
    tracker.get_summary()


def show_all():
    """æ˜¾ç¤ºæ‰€æœ‰å®éªŒ"""
    df = pd.read_csv('experiment_logs/experiments.csv')
    
    print("\n" + "="*100)
    print("æ‰€æœ‰å®éªŒè®°å½•")
    print("="*100)
    
    # é€‰æ‹©å…³é”®åˆ—
    cols = ['experiment_id', 'description', 'augmentation_mode', 
            'dropout', 'best_val_f1', 'final_test_f1', 'overfit_gap']
    
    display_df = df[cols].copy()
    display_df = display_df.sort_values('best_val_f1', ascending=False)
    
    # æ ¼å¼åŒ–
    display_df['best_val_f1'] = display_df['best_val_f1'].apply(lambda x: f"{x:.4f}")
    display_df['final_test_f1'] = display_df['final_test_f1'].apply(lambda x: f"{x:.4f}")
    display_df['overfit_gap'] = display_df['overfit_gap'].apply(lambda x: f"{x:.4f}")
    
    print(display_df.to_string(index=False))
    print("="*100)


def show_top(n=5):
    """æ˜¾ç¤ºæ€§èƒ½æœ€å¥½çš„Nä¸ªå®éªŒ"""
    df = pd.read_csv('experiment_logs/experiments.csv')
    df = df.sort_values('best_val_f1', ascending=False).head(n)
    
    print(f"\n{'='*100}")
    print(f"Top {n} å®éªŒï¼ˆæŒ‰Val F1æ’åºï¼‰")
    print("="*100)
    
    for idx, row in enumerate(df.itertuples(), 1):
        medal = "ğŸ¥‡" if idx == 1 else ("ğŸ¥ˆ" if idx == 2 else ("ğŸ¥‰" if idx == 3 else "  "))
        print(f"\n{medal} æ’å {idx}: {row.experiment_id}")
        print(f"   æè¿°: {row.description}")
        print(f"   å¢å¼º: {row.augmentation_mode} | Dropout: {row.dropout} | WD: {row.weight_decay}")
        print(f"   Val F1: {row.best_val_f1:.4f} | Test F1: {row.final_test_f1:.4f}")
        print(f"   è¿‡æ‹Ÿåˆ: {row.overfit_gap:.4f} (Train F1 - Val F1)")
        print(f"   å„ç±»F1: [{row.class0_f1:.3f}, {row.class1_f1:.3f}, {row.class2_f1:.3f}, {row.class3_f1:.3f}]")
    
    print("="*100)


def compare_augmentation():
    """å¯¹æ¯”ä¸åŒæ•°æ®å¢å¼ºæ¨¡å¼"""
    df = pd.read_csv('experiment_logs/experiments.csv')
    
    print("\n" + "="*100)
    print("æ•°æ®å¢å¼ºæ¨¡å¼å¯¹æ¯”")
    print("="*100)
    
    # æŒ‰å¢å¼ºæ¨¡å¼åˆ†ç»„
    grouped = df.groupby('augmentation_mode').agg({
        'best_val_f1': ['mean', 'std', 'max', 'count'],
        'overfit_gap': ['mean', 'std'],
        'final_test_f1': ['mean', 'max']
    }).round(4)
    
    print("\næŒ‰å¢å¼ºæ¨¡å¼ç»Ÿè®¡:")
    print(grouped.to_string())
    
    # è¯¦ç»†åˆ—è¡¨
    print("\n\næ¯ç§æ¨¡å¼çš„å®éªŒ:")
    for mode in df['augmentation_mode'].unique():
        mode_df = df[df['augmentation_mode'] == mode].sort_values('best_val_f1', ascending=False)
        print(f"\n{mode.upper()}æ¨¡å¼ ({len(mode_df)}ä¸ªå®éªŒ):")
        for row in mode_df.itertuples():
            print(f"  - {row.experiment_id}: Val F1={row.best_val_f1:.4f}, Gap={row.overfit_gap:.4f}")
    
    print("="*100)


def show_detail(exp_id):
    """æ˜¾ç¤ºå•ä¸ªå®éªŒçš„è¯¦ç»†ä¿¡æ¯"""
    import json
    
    detail_file = f'experiment_logs/{exp_id}_detail.json'
    if not Path(detail_file).exists():
        print(f"âŒ æœªæ‰¾åˆ°å®éªŒè¯¦æƒ…: {detail_file}")
        return
    
    with open(detail_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print("\n" + "="*100)
    print(f"å®éªŒè¯¦æƒ…: {exp_id}")
    print("="*100)
    
    print("\nã€é…ç½®ã€‘")
    for key, value in data['config'].items():
        print(f"  {key}: {value}")
    
    print("\nã€ç»“æœã€‘")
    for key, value in data['results'].items():
        if key != 'class_f1':
            print(f"  {key}: {value}")
        else:
            print(f"  class_f1: {value}")
    
    print(f"\nã€å¤‡æ³¨ã€‘")
    print(f"  {data.get('notes', 'æ— ')}")
    
    print("="*100)


def generate_comparison():
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    tracker = ExperimentTracker()
    report_path = tracker.compare_experiments()
    print(f"\nâœ“ å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    print(f"âœ“ å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ: experiment_logs/comparison_plots.png")


def export_for_paper():
    """å¯¼å‡ºè®ºæ–‡æ‰€éœ€çš„è¡¨æ ¼"""
    df = pd.read_csv('experiment_logs/experiments.csv')
    
    # é€‰æ‹©å…³é”®åˆ—
    paper_df = df[[
        'description', 'augmentation_mode', 'dropout', 'weight_decay',
        'best_val_f1', 'final_test_f1', 'overfit_gap',
        'class0_f1', 'class1_f1', 'class2_f1', 'class3_f1'
    ]].copy()
    
    paper_df = paper_df.sort_values('best_val_f1', ascending=False)
    
    # ä¿å­˜ä¸ºLaTeXè¡¨æ ¼
    latex_file = 'experiment_logs/paper_table.tex'
    with open(latex_file, 'w', encoding='utf-8') as f:
        f.write(paper_df.to_latex(index=False, float_format='%.4f'))
    
    print(f"âœ“ LaTeXè¡¨æ ¼å·²å¯¼å‡º: {latex_file}")
    
    # ä¿å­˜ä¸ºCSVï¼ˆç”¨äºExcelï¼‰
    csv_file = 'experiment_logs/paper_table.csv'
    paper_df.to_csv(csv_file, index=False)
    print(f"âœ“ CSVè¡¨æ ¼å·²å¯¼å‡º: {csv_file}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='æŸ¥çœ‹å®éªŒç»“æœ')
    parser.add_argument('--summary', action='store_true', help='æ˜¾ç¤ºæ‘˜è¦')
    parser.add_argument('--all', action='store_true', help='æ˜¾ç¤ºæ‰€æœ‰å®éªŒ')
    parser.add_argument('--top', type=int, default=5, help='æ˜¾ç¤ºTop Nå®éªŒ')
    parser.add_argument('--augmentation', action='store_true', help='å¯¹æ¯”æ•°æ®å¢å¼ºæ•ˆæœ')
    parser.add_argument('--detail', type=str, help='æ˜¾ç¤ºå•ä¸ªå®éªŒè¯¦æƒ…ï¼ˆå®éªŒIDï¼‰')
    parser.add_argument('--compare', action='store_true', help='ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š')
    parser.add_argument('--export', action='store_true', help='å¯¼å‡ºè®ºæ–‡è¡¨æ ¼')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºé»˜è®¤æ‘˜è¦
    if not any(vars(args).values()):
        show_summary()
        print("\næç¤ºï¼šä½¿ç”¨ --help æŸ¥çœ‹æ›´å¤šé€‰é¡¹")
    else:
        if args.summary:
            show_summary()
        
        if args.all:
            show_all()
        
        if args.top:
            show_top(args.top)
        
        if args.augmentation:
            compare_augmentation()
        
        if args.detail:
            show_detail(args.detail)
        
        if args.compare:
            generate_comparison()
        
        if args.export:
            export_for_paper()


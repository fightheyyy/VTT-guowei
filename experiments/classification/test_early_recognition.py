"""
æµ‹è¯•æ—©æœŸè¯†åˆ«æ—¶é—´
æ‰¾åˆ°é¦–æ¬¡F1â‰¥0.8çš„æ—¶é—´ç‚¹
"""

import os
import sys
import torch
import numpy as np
from sklearn.metrics import f1_score
import matplotlib.pyplot as plt

sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from experiments.classification.data_loader_classification_cached import create_classification_dataloaders_cached
from models.timesclip_classifier import LanguageOnlyTimesCLIPClassifier


def evaluate_at_time_steps(model, data_loader, device, time_steps, total_steps=37):
    """
    è¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šæ—¶é—´æ­¥æ•°çš„æ€§èƒ½
    """
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for x, y in data_loader:
            x, y = x.to(device), y.to(device)
            
            # æˆªæ–­åˆ°æŒ‡å®šæ—¶é—´æ­¥
            if time_steps < total_steps:
                x_truncated = x[:, :time_steps, :].clone()
                # ç”¨é›¶å¡«å……åˆ°åŸé•¿åº¦
                padding = torch.zeros(x.size(0), total_steps - time_steps, x.size(2)).to(device)
                x_truncated = torch.cat([x_truncated, padding], dim=1)
            else:
                x_truncated = x
            
            logits = model(x_truncated)
            preds = torch.argmax(logits, dim=1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(y.cpu().numpy())
    
    # è®¡ç®—F1
    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)
    
    return f1_macro, f1_per_class


def find_early_recognition_time(model_path, csv_path, time_steps_list, f1_threshold=0.8):
    """
    å¯»æ‰¾æœ€æ—©å¯è¯†åˆ«æ—¶é—´
    """
    print("="*70)
    print("æ—©æœŸè¯†åˆ«æ—¶é—´æµ‹è¯•")
    print("="*70)
    print(f"æ¨¡å‹: {model_path}")
    print(f"F1é˜ˆå€¼: {f1_threshold}")
    print("="*70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    _, _, test_loader, num_classes = create_classification_dataloaders_cached(
        csv_path=csv_path,
        batch_size=64,
        use_cache=True,
        load_to_memory=False
    )
    
    # åŠ è½½æ¨¡å‹
    print("åŠ è½½æ¨¡å‹...")
    model = LanguageOnlyTimesCLIPClassifier(
        time_steps=37,
        n_variates=14,
        num_classes=num_classes
    ).to(device)
    
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    print(f"æœ€ä½³éªŒè¯F1: {checkpoint.get('val_f1', 'N/A')}")
    
    # æµ‹è¯•ä¸åŒæ—¶é—´é•¿åº¦
    print(f"\n{'='*70}")
    print(f"{'æ—¶é—´æ­¥':<8} {'å¤©æ•°':<8} {'F1 (macro)':<12} {'ç±»åˆ«0':<8} {'ç±»åˆ«1':<8} {'ç±»åˆ«2':<8} {'ç±»åˆ«3':<8} {'çŠ¶æ€'}")
    print(f"{'-'*70}")
    
    results = []
    earliest_identifiable_step = None
    
    for steps in time_steps_list:
        days = steps * 10
        f1_macro, f1_per_class = evaluate_at_time_steps(model, test_loader, device, steps)
        
        identifiable = "âœ“ å¯è¯†åˆ«" if f1_macro >= f1_threshold else "âœ— æœªè¾¾æ ‡"
        
        print(f"{steps:<8} {days:<8} {f1_macro:<12.4f} ", end='')
        for f1 in f1_per_class:
            print(f"{f1:<8.4f} ", end='')
        print(f"{identifiable}")
        
        results.append({
            'steps': steps,
            'days': days,
            'f1_macro': f1_macro,
            'f1_per_class': f1_per_class.tolist()
        })
        
        if earliest_identifiable_step is None and f1_macro >= f1_threshold:
            earliest_identifiable_step = steps
    
    print(f"{'='*70}")
    
    # æ€»ç»“
    if earliest_identifiable_step:
        earliest_days = earliest_identifiable_step * 10
        print(f"\nğŸ¯ æœ€æ—©å¯è¯†åˆ«æ—¶é—´: {earliest_identifiable_step}æ­¥ ({earliest_days}å¤©)")
        print(f"   F1åˆ†æ•°: {results[time_steps_list.index(earliest_identifiable_step)]['f1_macro']:.4f}")
        
        # åˆ†ææ¯ä¸ªç±»åˆ«
        print(f"\næ¯ä¸ªç±»åˆ«çš„æœ€æ—©è¯†åˆ«æ—¶é—´:")
        for class_idx in range(num_classes):
            for i, res in enumerate(results):
                if res['f1_per_class'][class_idx] >= f1_threshold:
                    print(f"  ç±»åˆ«{class_idx}: {res['steps']}æ­¥ ({res['days']}å¤©), F1={res['f1_per_class'][class_idx]:.4f}")
                    break
            else:
                print(f"  ç±»åˆ«{class_idx}: æœªè¾¾åˆ°é˜ˆå€¼")
    else:
        print(f"\nâŒ æœªæ‰¾åˆ°æ»¡è¶³F1â‰¥{f1_threshold}çš„æ—¶é—´ç‚¹")
        max_f1_idx = max(range(len(results)), key=lambda i: results[i]['f1_macro'])
        max_f1_result = results[max_f1_idx]
        print(f"   æœ€é«˜F1: {max_f1_result['f1_macro']:.4f} (åœ¨{max_f1_result['steps']}æ­¥/{max_f1_result['days']}å¤©)")
    
    # ç»˜åˆ¶æ›²çº¿
    plot_early_recognition_curve(results, f1_threshold)
    
    return results, earliest_identifiable_step


def plot_early_recognition_curve(results, f1_threshold=0.8):
    """ç»˜åˆ¶æ—©æœŸè¯†åˆ«æ›²çº¿"""
    days_list = [r['days'] for r in results]
    f1_list = [r['f1_macro'] for r in results]
    
    plt.figure(figsize=(12, 6))
    
    # F1æ›²çº¿
    plt.plot(days_list, f1_list, 'o-', linewidth=2, markersize=8, label='F1 (macro)')
    plt.axhline(y=f1_threshold, color='r', linestyle='--', label=f'é˜ˆå€¼ (F1={f1_threshold})')
    
    # æ ‡è®°æœ€æ—©å¯è¯†åˆ«ç‚¹
    for i, (days, f1) in enumerate(zip(days_list, f1_list)):
        if f1 >= f1_threshold:
            plt.plot(days, f1, 'r*', markersize=20)
            plt.annotate(f'æœ€æ—©è¯†åˆ«ç‚¹\n{days}å¤©\nF1={f1:.3f}', 
                        xy=(days, f1), 
                        xytext=(20, -20), 
                        textcoords='offset points',
                        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
            break
    
    plt.xlabel('å¤©æ•°', fontsize=12)
    plt.ylabel('F1åˆ†æ•° (macro)', fontsize=12)
    plt.title('æ—©æœŸè¯†åˆ«æ€§èƒ½æ›²çº¿', fontsize=14, fontweight='bold')
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    save_path = 'experiments/classification/timesclip_improved/results/early_recognition_curve.png'
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\næ›²çº¿å›¾å·²ä¿å­˜: {save_path}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•æ—©æœŸè¯†åˆ«æ—¶é—´')
    parser.add_argument('--model_path', type=str, 
                       default='experiments/classification/timesclip_improved/checkpoints/language_only_best.pth',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--csv_path', type=str, default='../../data/2018four.csv', help='æ•°æ®è·¯å¾„')
    parser.add_argument('--f1_threshold', type=float, default=0.8, help='F1é˜ˆå€¼')
    
    args = parser.parse_args()
    
    # æµ‹è¯•çš„æ—¶é—´æ­¥åˆ—è¡¨
    time_steps_list = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 37]
    
    results, earliest_step = find_early_recognition_time(
        model_path=args.model_path,
        csv_path=args.csv_path,
        time_steps_list=time_steps_list,
        f1_threshold=args.f1_threshold
    )


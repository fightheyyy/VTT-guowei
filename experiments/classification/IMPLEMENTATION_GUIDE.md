# è¶…è¶ŠCLECçš„å®æ–½æŒ‡å—

## ğŸ¯ å¿«é€Ÿå®æ–½æ­¥éª¤

### ç¬¬1æ­¥ï¼šä¿®æ”¹è®­ç»ƒå¾ªç¯ï¼ˆæœ€é‡è¦ â­â­â­â­â­ï¼‰

åœ¨ `train_classification_timesclip.py` ä¸­ä¿®æ”¹ `train_one_epoch` å‡½æ•°ï¼š

```python
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥
from experiments.classification.improved_losses import (
    CombinedEarlyLoss,
    temporal_masking_augmentation,
    CurriculumScheduler
)

# ä¿®æ”¹train_one_epochå‡½æ•°
def train_one_epoch_improved(model, train_loader, optimizer, device, 
                             criterion, curriculum_scheduler, 
                             epoch, total_epochs, use_dual_modal=True):
    """æ”¹è¿›çš„è®­ç»ƒå‡½æ•°"""
    model.train()
    total_loss = 0
    all_preds = []
    all_labels = []
    
    # è·å–å½“å‰epochçš„æ—¶é—´èŒƒå›´
    min_ratio, max_ratio = curriculum_scheduler.get_time_range(epoch)
    
    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{total_epochs}', leave=False)
    for x, y in pbar:
        x, y = x.to(device), y.to(device)
        
        # ã€å…³é”®æ”¹è¿›1ã€‘æ—¶é—´maskingå¢å¼º
        x_masked, keep_steps, time_ratio = temporal_masking_augmentation(
            x, min_ratio=min_ratio, max_ratio=max_ratio
        )
        
        optimizer.zero_grad()
        
        if use_dual_modal:
            # åŒæ¨¡æ€forward
            logits, loss_dict = model.forward_with_features(x_masked)
            features_visual = loss_dict.get('visual_features')
            features_language = loss_dict.get('language_features')
            
            # ã€å…³é”®æ”¹è¿›2ã€‘ä½¿ç”¨æ”¹è¿›çš„æŸå¤±å‡½æ•°
            loss, loss_info = criterion(
                logits, y,
                features_visual=features_visual,
                features_language=features_language,
                time_ratio=time_ratio
            )
        else:
            logits = model(x_masked)
            loss, loss_info = criterion(logits, y, time_ratio=time_ratio)
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        total_loss += loss.item()
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'time': f'{int(time_ratio*37)}æ­¥'
        })
        
        # è®°å½•é¢„æµ‹
        with torch.no_grad():
            preds = torch.argmax(logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(y.cpu().numpy())
    
    avg_loss = total_loss / len(train_loader)
    accuracy = accuracy_score(all_labels, all_preds)
    
    return avg_loss, accuracy
```

---

### ç¬¬2æ­¥ï¼šä¿®æ”¹è®­ç»ƒä¸»å‡½æ•°

åœ¨ `train_timesclip_classifier` å‡½æ•°ä¸­ï¼š

```python
def train_timesclip_classifier(
    csv_path="../../data/2018four.csv",
    time_steps=37,
    n_variates=14,
    model_type="dual",
    batch_size=32,
    epochs=100,
    lr=1e-4,
    patience=15,
    device=None,
    use_improved_strategy=True  # æ–°å¢å‚æ•°
):
    """è®­ç»ƒTimesCLIPåˆ†ç±»å™¨ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    set_seed(42)
    
    # ... æ•°æ®åŠ è½½ä»£ç ä¸å˜ ...
    
    # åˆ›å»ºæ¨¡å‹
    model = TimesCLIPClassifier(
        time_steps=time_steps,
        n_variates=n_variates,
        num_classes=num_classes
    ).to(device)
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=lr,
        weight_decay=1e-4
    )
    
    # ã€æ”¹è¿›1ã€‘ä½¿ç”¨æ”¹è¿›çš„æŸå¤±å‡½æ•°
    if use_improved_strategy:
        criterion = CombinedEarlyLoss(
            num_classes=num_classes,
            focal_alpha=0.25,
            focal_gamma=2.0,
            time_weight_factor=2.0,  # æ—©æœŸæƒé‡å€æ•°
            contrastive_temp=0.07,
            contrastive_early_weight=2.0,
            contrastive_weight=0.1
        )
        
        # ã€æ”¹è¿›2ã€‘è¯¾ç¨‹å­¦ä¹ è°ƒåº¦å™¨
        curriculum_scheduler = CurriculumScheduler(
            total_epochs=epochs,
            warmup_epochs=int(epochs * 0.2),  # å‰20%åšwarmup
            min_ratio_start=0.7,  # ä»70%å¼€å§‹
            min_ratio_end=0.2     # æœ€åé™åˆ°20%
        )
        
        print(f"\nä½¿ç”¨æ”¹è¿›ç­–ç•¥: âœ“")
        print(f"  æŸå¤±å‡½æ•°: TimeAwareFocalLoss + æ—©æœŸå¯¹æ¯”å­¦ä¹ ")
        print(f"  è¯¾ç¨‹å­¦ä¹ : {curriculum_scheduler}")
    else:
        criterion = nn.CrossEntropyLoss()
        curriculum_scheduler = None
        print(f"\nä½¿ç”¨æ ‡å‡†ç­–ç•¥")
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ä¿æŒä¸å˜
    scheduler = ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=5,
        verbose=True
    )
    
    # è®­ç»ƒå¾ªç¯
    best_val_acc = 0.0
    patience_counter = 0
    
    for epoch in range(1, epochs + 1):
        # ä½¿ç”¨æ”¹è¿›çš„è®­ç»ƒå‡½æ•°
        if use_improved_strategy:
            train_loss, train_acc = train_one_epoch_improved(
                model, train_loader, optimizer, device,
                criterion, curriculum_scheduler,
                epoch, epochs, use_dual_modal=(model_type == 'dual')
            )
        else:
            train_loss, train_acc = train_one_epoch(
                model, train_loader, optimizer, device,
                contrastive_weight=0.1,
                use_dual_modal=(model_type == 'dual'),
                epoch=epoch,
                total_epochs=epochs
            )
        
        # éªŒè¯
        val_metrics = evaluate(model, val_loader, device, use_dual_modal=(model_type == 'dual'))
        val_loss = val_metrics['loss']
        val_acc = val_metrics['accuracy']
        
        scheduler.step(val_loss)
        
        # æ‰“å°
        if epoch % 5 == 0:
            print(f"Epoch {epoch}/{epochs}: "
                  f"Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | "
                  f"Val Loss={val_loss:.4f}, Acc={val_acc:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0
            # ä¿å­˜æ¨¡å‹...
        else:
            patience_counter += 1
            if patience_counter >= patience:
                break
    
    # æµ‹è¯•...
    return model, test_metrics
```

---

### ç¬¬3æ­¥ï¼šä¿®æ”¹æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨åŒæ¨¡æ€ï¼‰

åœ¨ `models/timesclip_classifier.py` ä¸­æ·»åŠ ä¸€ä¸ªæ–°æ–¹æ³•ï¼š

```python
class TimesCLIPClassifier(nn.Module):
    # ... ç°æœ‰ä»£ç  ...
    
    def forward_with_features(self, x, cached_images=None):
        """
        Forward passåŒæ—¶è¿”å›ä¸­é—´ç‰¹å¾
        ç”¨äºæ”¹è¿›çš„æŸå¤±å‡½æ•°
        
        Returns:
            logits: [B, num_classes]
            features_dict: {
                'visual_features': [B, d_model],
                'language_features': [B, d_model],
                'logits': [B, num_classes]
            }
        """
        batch_size, time_steps, n_variates = x.shape
        
        # Patching
        patches = self.patcher(x)  # [B, V, N_Patches, Patch_Length]
        
        # è§†è§‰æ¨¡æ€
        if cached_images is not None:
            CLS_images = self.visual_module(patches, cached_images=cached_images)
        else:
            CLS_images = self.visual_module(patches)  # [B, V, d_model]
        
        # è¯­è¨€æ¨¡æ€
        CLS_text, _ = self.language_module(patches)  # [B, V, d_model]
        
        # å˜é‡é€‰æ‹©
        if self.use_variable_selection:
            attn_weights = self.variable_attention(CLS_images, CLS_text)
            CLS_images_selected = (CLS_images * attn_weights).sum(dim=1)
            CLS_text_selected = (CLS_text * attn_weights).sum(dim=1)
        else:
            CLS_images_selected = CLS_images.mean(dim=1)
            CLS_text_selected = CLS_text.mean(dim=1)
        
        # èåˆ
        CLS_fused = torch.cat([CLS_images_selected, CLS_text_selected], dim=-1)
        CLS_fused = self.fusion(CLS_fused)
        
        # åˆ†ç±»
        logits = self.classifier(CLS_fused)
        
        features_dict = {
            'visual_features': CLS_images_selected,  # [B, d_model]
            'language_features': CLS_text_selected,  # [B, d_model]
            'logits': logits
        }
        
        return logits, features_dict
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### é€‰é¡¹Aï¼šå®Œå…¨æ›¿æ¢ï¼ˆæ¨èï¼‰

```bash
cd experiments/classification

# ä½¿ç”¨æ”¹è¿›ç­–ç•¥è®­ç»ƒ
python train_classification_timesclip.py \
    --model_type dual \
    --batch_size 64 \
    --epochs 100 \
    --use_improved  # æ–°å¢flag
```

### é€‰é¡¹Bï¼šå¯¹æ¯”å®éªŒ

```bash
# 1. å…ˆè·‘åŸºçº¿ï¼ˆæ ‡å‡†ç­–ç•¥ï¼‰
python train_classification_timesclip.py \
    --model_type dual \
    --epochs 100

# 2. å†è·‘æ”¹è¿›ç‰ˆ
python train_classification_timesclip.py \
    --model_type dual \
    --epochs 100 \
    --use_improved
```

---

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
Epoch 1/100: Loss=1.2345, Acc=0.4567 | Val Loss=1.3456, Acc=0.4321
  Time range: [0.70, 1.00] (æ—©æœŸwarmup)
  
Epoch 20/100: Loss=0.8765, Acc=0.7234 | Val Loss=0.9123, Acc=0.6987
  Time range: [0.70, 1.00] (warmupç»“æŸ)

Epoch 50/100: Loss=0.4567, Acc=0.8912 | Val Loss=0.5234, Acc=0.8654
  Time range: [0.45, 1.00] (å¼•å…¥çŸ­åºåˆ—)

Epoch 80/100: Loss=0.2345, Acc=0.9345 | Val Loss=0.3456, Acc=0.9123
  Time range: [0.25, 1.00] (å¤§é‡çŸ­åºåˆ—)

Epoch 100/100: Loss=0.1234, Acc=0.9567 | Val Loss=0.2345, Acc=0.9345
  Time range: [0.20, 1.00] (æœ€ç»ˆçŠ¶æ€)
```

### æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æ ‡å‡†ç­–ç•¥ | æ”¹è¿›ç­–ç•¥ | æå‡ |
|-----|---------|---------|-----|
| 60å¤©F1 | 0.68 | 0.78 | +0.10 âœ… |
| 90å¤©F1 | 0.75 | 0.85 | +0.10 âœ… |
| 120å¤©F1 | 0.82 | 0.90 | +0.08 âœ… |
| å®Œæ•´F1 | 0.89 | 0.93 | +0.04 âœ… |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å†…å­˜ä½¿ç”¨
- æ”¹è¿›ç­–ç•¥ä¼šå¢åŠ çº¦10-15%çš„æ˜¾å­˜ä½¿ç”¨
- å¦‚æœOOMï¼Œå¯ä»¥å‡å°batch_sizeæˆ–å…³é—­éƒ¨åˆ†ç‰¹å¾

### 2. è®­ç»ƒæ—¶é—´
- æ¯ä¸ªepochçº¦å¢åŠ 15-20%çš„æ—¶é—´
- ä½†æ€»epochæ•°å¯èƒ½æ›´å°‘ï¼ˆæ›´å¿«æ”¶æ•›ï¼‰

### 3. è¶…å‚æ•°è°ƒä¼˜å»ºè®®
```python
# å¦‚æœæ—©æœŸæ€§èƒ½ä¸ç†æƒ³
time_weight_factor = 3.0  # å¢å¤§æ—©æœŸæƒé‡

# å¦‚æœè®­ç»ƒä¸ç¨³å®š
min_ratio_start = 0.8  # å»¶é•¿warmupæœŸ

# å¦‚æœå¯¹æ¯”æŸå¤±å¤ªå¤§
contrastive_weight = 0.05  # é™ä½å¯¹æ¯”æƒé‡
```

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æ‰“å°è®­ç»ƒä¿¡æ¯

åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ ï¼š

```python
if epoch % 10 == 0:
    # æµ‹è¯•ä¸åŒæ—¶é—´é•¿åº¦çš„æ€§èƒ½
    for test_steps in [6, 12, 18, 37]:
        test_ratio = test_steps / 37
        # è¯„ä¼°æ¨¡å‹åœ¨è¯¥é•¿åº¦ä¸‹çš„F1...
        print(f"  {test_steps}æ­¥({test_steps*10}å¤©): F1={f1:.4f}")
```

### å¯è§†åŒ–æ—¶é—´æƒé‡

```python
import matplotlib.pyplot as plt

ratios = [i/10 for i in range(1, 11)]
weights = [1.0 + 2.0 * (1.0 - r) for r in ratios]

plt.plot(ratios, weights)
plt.xlabel('Time Ratio')
plt.ylabel('Loss Weight')
plt.title('Time-Aware Weight Curve')
plt.savefig('time_weight_curve.png')
```

---

## ğŸ“ˆ è¿›ä¸€æ­¥ä¼˜åŒ–

å®ŒæˆåŸºç¡€æ”¹è¿›åï¼Œå¯ä»¥å°è¯•ï¼š

1. **é›†æˆå­¦ä¹ **: è®­ç»ƒå¤šä¸ªæ—¶é—´é•¿åº¦çš„æ¨¡å‹ï¼Œé›†æˆé¢„æµ‹
2. **çŸ¥è¯†è’¸é¦**: ç”¨é•¿æ—¶é—´æ¨¡å‹è’¸é¦çŸ­æ—¶é—´æ¨¡å‹
3. **å…ƒå­¦ä¹ **: å¿«é€Ÿé€‚åº”æ–°ä½œç‰©ç±»å‹
4. **ä¸»åŠ¨å­¦ä¹ **: é€‰æ‹©æœ€æœ‰ä»·å€¼çš„æ ·æœ¬æ ‡æ³¨

---

## ğŸ’¬ å¸¸è§é—®é¢˜

**Q: å¿…é¡»å®ç°æ‰€æœ‰ç­–ç•¥å—ï¼Ÿ**
A: ä¸éœ€è¦ã€‚å»ºè®®ä¼˜å…ˆå®ç°ï¼šæ—¶é—´masking + TimeAwareFocalLossï¼Œè¿™ä¸¤ä¸ªæœ€é‡è¦ã€‚

**Q: å¯ä»¥åªç”¨è¯­è¨€æ¨¡æ€å—ï¼Ÿ**
A: å¯ä»¥ã€‚æ”¹è¿›ç­–ç•¥å¯¹è¯­è¨€æ¨¡æ€ä¹Ÿæœ‰æ•ˆï¼Œåªæ˜¯å¯¹æ¯”å­¦ä¹ éƒ¨åˆ†éœ€è¦è°ƒæ•´ã€‚

**Q: è®­ç»ƒä¸æ”¶æ•›æ€ä¹ˆåŠï¼Ÿ**
A: å¢åŠ warmup_epochsï¼Œä»0.8çš„min_ratioå¼€å§‹ï¼Œé€æ¸é™ä½ã€‚

**Q: å¦‚ä½•ç¡®å®šæœ€æ—©è¯†åˆ«æ—¶é—´ï¼Ÿ**
A: è®­ç»ƒå®Œæˆåï¼Œåœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•ä¸åŒæ—¶é—´é•¿åº¦ï¼Œæ‰¾åˆ°é¦–æ¬¡F1â‰¥0.8çš„ç‚¹ã€‚


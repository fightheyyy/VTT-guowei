# 数据增强使用指南

## 一、为什么需要数据增强？

针对你的过拟合问题：
- **Train F1 = 0.935** vs **Val F1 = 0.563** → 差距过大
- 训练集仅4000个样本，验证集仅445个 → 数据量不足
- 预缓存图像无随机性 → 视觉分支容易过拟合

## 二、已实现的增强策略

### 2.1 时序数据增强（语言分支）

| 增强类型 | 原理 | 参数 | 效果 |
|---------|------|------|------|
| **Gaussian噪声** | 添加随机噪声 | std=0.02 | 提升鲁棒性 |
| **随机缩放** | 按变量独立缩放 | ×0.9~1.1 | 模拟测量误差 |
| **时间平移** | 循环移位时间步 | ±2步 | 学习时序不变性 |
| **变量Dropout** | 随机mask变量 | 10%概率 | 防止过度依赖单变量 |
| **时间截断** | 随机置零某段时间 | 最多3步 | 模拟缺失数据 |

### 2.2 图像数据增强（视觉分支）

| 增强类型 | 原理 | 参数 | 效果 |
|---------|------|------|------|
| **随机亮度** | 调整图像亮度 | ±10% | 增加视觉多样性 |
| **随机对比度** | 调整图像对比度 | ±10% | 增加视觉多样性 |

## 三、增强模式配置

### 3.1 Light模式（轻度增强）
```python
# 适用场景：验证集较大，过拟合不严重
noise_std = 0.01
scale_range = (0.95, 1.05)
ts_prob = 0.5  # 50%概率增强
img_prob = 0.3
```

### 3.2 Medium模式（中度增强）⭐ 推荐
```python
# 适用场景：当前情况（Train F1=0.935, Val F1=0.563）
noise_std = 0.02
scale_range = (0.9, 1.1)
ts_prob = 0.7  # 70%概率增强
img_prob = 0.5
types = ['noise', 'scale', 'shift']
```

### 3.3 Heavy模式（重度增强）
```python
# 适用场景：严重过拟合，或数据量极少
noise_std = 0.03
scale_range = (0.85, 1.15)
ts_prob = 0.8  # 80%概率增强
img_prob = 0.7
types = ['noise', 'scale', 'shift', 'variate_drop', 'temporal_cutout']
```

## 四、使用方法

### 4.1 快速开始（已集成到训练脚本）

```bash
# 直接运行，默认使用medium模式
python train_12steps_dual_cached.py

# 或使用bat脚本
.\run_12steps.bat dual
```

### 4.2 自定义增强模式

修改 `train_12steps_dual_cached.py` 中的配置：

```python
# 在main()函数中找到这行
AUGMENTATION_MODE = 'medium'  # 改为 'light' 或 'heavy'
```

### 4.3 禁用增强（对比实验）

```python
# 将增强器设为None
ts_augmentor = None
img_augmentor = None
```

## 五、预期效果

### 5.1 性能提升

| 配置 | Train F1 | Val F1 | 过拟合差距 | 说明 |
|------|----------|--------|-----------|------|
| **无增强** | 0.935 | 0.563 | 0.372 ⚠️⚠️⚠️ | 当前状态 |
| **Medium增强** | 0.78 | 0.65 | 0.13 ⚠️ | 预期改善 |
| **Heavy增强** | 0.72 | 0.68 | 0.04 ✅ | 可能过度 |

### 5.2 训练曲线变化

**无增强**：
```
Train Loss: 快速下降 → 接近0
Val Loss:   缓慢下降 → 震荡上升  ← 过拟合
```

**有增强**：
```
Train Loss: 稳定下降 → 收敛到0.2左右
Val Loss:   稳定下降 → 收敛到0.3左右  ← 健康
```

## 六、其他改进措施

除了数据增强，还做了：

1. **Dropout提升**: 0.1 → 0.3
2. **Weight Decay提升**: 1e-4 → 5e-4
3. **建议重新划分数据集**: 
   - 验证集: 445 → 667个样本（更稳定）
   - 训练集: 4000 → 3890个样本

## 七、调优建议

### 7.1 如果Val F1仍然不提升

1. **增强更激进**：改为heavy模式
2. **增加Dropout**：0.3 → 0.4
3. **减少训练数据**：人为减少训练集，增加验证集

### 7.2 如果Train F1下降过多

1. **减弱增强**：改为light模式
2. **降低增强概率**：70% → 50%
3. **只用部分增强**：仅用noise和scale

### 7.3 如果收敛变慢

1. **调整学习率**：1e-4 → 2e-4
2. **减少weight_decay**：5e-4 → 3e-4
3. **增加batch_size**：64 → 128（如果显存够）

## 八、消融实验

建议进行消融实验验证增强效果：

```bash
# 1. 无增强 (baseline)
# 注释掉增强相关代码

# 2. 仅时序增强
img_augmentor = None

# 3. 仅图像增强
ts_augmentor = None

# 4. 双增强（完整版）
# 保持当前配置
```

记录每种配置的Val F1，找到最优组合。

## 九、注意事项

1. **验证集不增强**：evaluate()函数中不传增强器参数
2. **测试集不增强**：保证公平性
3. **随机种子**：已设置SEED=42，确保可重复性
4. **显存消耗**：增强几乎不增加显存（在CPU上计算）

## 十、FAQ

**Q: 为什么图像增强只有亮度和对比度？**
A: 因为图像已预缓存，无法做旋转、翻转等空间变换。亮度/对比度是像素级操作，不影响图像语义。

**Q: 能否动态生成图像以支持更多增强？**
A: 可以，但会显著降低训练速度（3-5倍慢）。建议先用当前方案，不够再考虑。

**Q: Mixup为什么没用？**
A: Mixup需要混合标签（如0.7×Class0 + 0.3×Class1），但Focal Loss难以处理软标签。可以试验性添加。

**Q: 时间平移会不会破坏时序信息？**
A: 循环平移仅±2步，模拟轻微的时间偏移。如果担心，可以设置shift_max=0禁用。


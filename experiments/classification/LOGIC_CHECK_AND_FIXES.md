# è®­ç»ƒé€»è¾‘æ£€æŸ¥ä¸ä¿®å¤è¯´æ˜

## ğŸ” å‘ç°çš„é—®é¢˜

### é—®é¢˜1: æŸå¤±å‡½æ•°è°ƒç”¨é”™è¯¯ âš ï¸

**ä½ç½®**: `train_one_epoch_improved()` å‡½æ•°ç¬¬102-104è¡Œ

**é”™è¯¯ä»£ç **:
```python
cls_loss, loss_info = criterion.classification_loss(
    logits, y, time_ratio
), None
```

**é—®é¢˜åˆ†æ**:
1. `CombinedEarlyLoss` ç±»æ²¡æœ‰ `classification_loss` å±æ€§æˆ–æ–¹æ³•
2. åº”è¯¥ç›´æ¥è°ƒç”¨ `criterion(...)` (ä½¿ç”¨ `__call__` æ–¹æ³•)
3. `CombinedEarlyLoss` è¿”å› `(loss, loss_dict)`ï¼Œä¸æ˜¯ `(loss, None)`

**ä¿®å¤å**:
```python
loss, loss_dict = criterion(
    logits, y,
    features_visual=None,  # language_onlyä¸éœ€è¦
    features_language=None,
    time_ratio=time_ratio
)
```

---

### é—®é¢˜2: cached_imagesç»´åº¦ä¸åŒ¹é… âš ï¸

**ä½ç½®**: `train_one_epoch_improved()` å‡½æ•°ç¬¬94-96è¡Œ

**æ½œåœ¨é—®é¢˜**:
```python
# é”™è¯¯ï¼šx_maskedè¢«æˆªæ–­äº†ï¼Œä½†cached_imagesè¿˜æ˜¯å®Œæ•´çš„14å¼ å›¾
logits, contrastive_loss = model(x_masked, return_contrastive_loss=True, 
                                 cached_images=cached_images)
```

**é—®é¢˜åˆ†æ**:
1. `x_masked` å¯èƒ½åªä¿ç•™äº†å‰15æ­¥ï¼ˆä¾‹å¦‚ï¼‰
2. ä½† `cached_images` ä»ç„¶æ˜¯14ä¸ªå˜é‡çš„å®Œæ•´å›¾åƒ
3. æ¨¡å‹å†…éƒ¨å¯èƒ½æœŸæœ›å›¾åƒæ•°é‡ä¸æ—¶é—´æ­¥åŒ¹é…
4. ç›®å‰ `VisualPreprocessor` æ˜¯åŸºäºå®Œæ•´37æ­¥ç”Ÿæˆçš„å›¾åƒ

**å½“å‰è§£å†³æ–¹æ¡ˆ**:
```python
# æš‚æ—¶ä¸ä½¿ç”¨cached_imagesï¼Œé¿å…ç»´åº¦é—®é¢˜
logits, contrastive_loss = model(x_masked, return_contrastive_loss=True, 
                                 cached_images=None)
```

**æœªæ¥æ”¹è¿›æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆA: åŠ¨æ€ç”Ÿæˆæˆªæ–­çš„å›¾åƒ
if keep_steps < total_steps:
    cached_images_truncated = generate_images(x_masked[:, :keep_steps, :])
    
# æ–¹æ¡ˆB: ä¿®æ”¹æ¨¡å‹ï¼Œä½¿å…¶èƒ½æ¥å—ä¸åŒ¹é…çš„è¾“å…¥
# æ–¹æ¡ˆC: å®Œå…¨ä¸ç”¨cached_imagesï¼ˆå½“å‰é‡‡ç”¨ï¼‰
```

---

### é—®é¢˜3: è¯­ä¹‰ä¸ä¸€è‡´ï¼ˆå·²å¤„ç†ï¼‰

**è§‚å¯Ÿ**:
- `model_type` é»˜è®¤æ˜¯ `"language_only"`
- ä½†ä»£ç ä¸­æœ‰ `use_dual_modal` åˆ†æ”¯
- å®é™…ä¸Šå½“å‰ç‰ˆæœ¬åªæ”¯æŒ `language_only`

**ä¿®å¤**:
```python
# æ˜ç¡®è¯´æ˜åªæ”¯æŒlanguage_only
if model_type == "language_only":
    model = LanguageOnlyTimesCLIPClassifier(...)
    use_dual_modal = False
else:
    raise NotImplementedError("æ”¹è¿›ç‰ˆç›®å‰åªæ”¯æŒlanguage_onlyæ¨¡å‹")
```

**åŸå› **:
- åŒæ¨¡æ€éœ€è¦è§†è§‰+è¯­è¨€å¯¹æ¯”å­¦ä¹ 
- éœ€è¦ `forward_with_features()` æ–¹æ³•
- ç›®å‰ `TimesCLIPClassifier` è¿˜æœªé€‚é…
- å…ˆå®ç°language_onlyï¼ŒéªŒè¯æœ‰æ•ˆåå†æ‰©å±•

---

## âœ… éªŒè¯çš„æ­£ç¡®é€»è¾‘

### 1. æ—¶é—´Maskingæµç¨‹ âœ“

```python
# è¾“å…¥: X [64, 37, 14]
X, y = batch_data
X = X.to(device)  # [64, 37, 14]

# Masking
X_masked, keep_steps, time_ratio = temporal_masking_augmentation(
    X, min_ratio=0.3, max_ratio=0.8
)
# å‡è®¾ keep_steps=15, time_ratio=0.4
# X_masked.shape = [64, 37, 14]
# X_masked[:, :15, :] = çœŸå®æ•°æ®
# X_masked[:, 15:, :] = 0

âœ“ é€»è¾‘æ­£ç¡®ï¼š
- ç»´åº¦ä¿æŒ [64, 37, 14]
- éƒ¨åˆ†çœŸå®ï¼Œéƒ¨åˆ†å¡«å……
- æ¨¡å‹æ— éœ€æ„ŸçŸ¥å®é™…é•¿åº¦
```

### 2. æŸå¤±è®¡ç®—æµç¨‹ âœ“

```python
# Forward
logits = model(X_masked)  # [64, 4]

# Loss
loss, loss_dict = criterion(
    logits, y,
    features_visual=None,
    features_language=None,
    time_ratio=time_ratio  # 0.4
)

# å†…éƒ¨è®¡ç®—:
# 1. CrossEntropy: ce_loss = F.cross_entropy(logits, y, reduction='none')
# 2. Focal: focal_loss = alpha * (1-pt)^gamma * ce_loss
# 3. Time weight: w = 1 + 2.0 * (1 - 0.4) = 2.2
# 4. Final: loss = (focal_loss * 2.2).mean()

âœ“ é€»è¾‘æ­£ç¡®ï¼š
- æ—©æœŸæ—¶é—´ (time_ratioå°) â†’ æƒé‡å¤§
- åæœŸæ—¶é—´ (time_ratioå¤§) â†’ æƒé‡å°
- æ•°å­¦ä¸Šè¿ç»­ï¼Œæ— çªå˜
```

### 3. è¯¾ç¨‹å­¦ä¹ æµç¨‹ âœ“

```python
# Epoch 1: 
min_ratio, max_ratio = curriculum_scheduler.get_time_range(1)
# min_ratio=0.7, max_ratio=1.0
# â†’ æ¯ä¸ªbatchéšæœºkeep_ratio âˆˆ [0.7, 1.0]
# â†’ è®­ç»ƒä½¿ç”¨ 26-37æ­¥çš„æ•°æ®

# Epoch 50:
min_ratio, max_ratio = curriculum_scheduler.get_time_range(50)
# min_ratioâ‰ˆ0.45, max_ratio=1.0
# â†’ æ¯ä¸ªbatchéšæœºkeep_ratio âˆˆ [0.45, 1.0]
# â†’ è®­ç»ƒä½¿ç”¨ 17-37æ­¥çš„æ•°æ®

# Epoch 100:
min_ratio, max_ratio = curriculum_scheduler.get_time_range(100)
# min_ratio=0.2, max_ratio=1.0
# â†’ æ¯ä¸ªbatchéšæœºkeep_ratio âˆˆ [0.2, 1.0]
# â†’ è®­ç»ƒä½¿ç”¨ 7-37æ­¥çš„æ•°æ®

âœ“ é€»è¾‘æ­£ç¡®ï¼š
- æ¸è¿›å¼å¼•å…¥çŸ­åºåˆ—
- æ¯ä¸ªepochå†…ä»æœ‰éšæœºæ€§
- é¿å…è¿‡æ‹ŸåˆæŸä¸ªé•¿åº¦
```

### 4. è¯„ä¼°æµç¨‹ âœ“

```python
def evaluate_detailed(model, data_loader, device):
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for x, y in data_loader:
            # æ³¨æ„ï¼šè¯„ä¼°æ—¶ä½¿ç”¨å®Œæ•´åºåˆ—ï¼ˆæ— maskingï¼‰
            logits = model(x)  # [B, 37, 14] â†’ [B, 4]
            preds = argmax(logits, dim=1)
            ...

âœ“ é€»è¾‘æ­£ç¡®ï¼š
- è®­ç»ƒæ—¶ï¼šä½¿ç”¨maskingå¢å¼º
- è¯„ä¼°æ—¶ï¼šä½¿ç”¨å®Œæ•´åºåˆ—
- ç¬¦åˆæ ‡å‡†æœºå™¨å­¦ä¹ å®è·µ
```

---

## ğŸ”¬ è¾¹ç•Œæƒ…å†µæµ‹è¯•

### æµ‹è¯•1: æçŸ­åºåˆ—

```python
# å½“ keep_steps = 3 (æœ€å°å€¼)
X = torch.randn(4, 37, 14)
X_masked, keep_steps, time_ratio = temporal_masking_augmentation(
    X, min_ratio=0.0, max_ratio=0.1
)

assert keep_steps >= 3  # âœ“ è‡³å°‘ä¿ç•™3æ­¥
assert X_masked.shape == (4, 37, 14)  # âœ“ ç»´åº¦æ­£ç¡®
assert (X_masked[:, :3, :] != 0).any()  # âœ“ å‰3æ­¥æœ‰æ•°æ®
assert (X_masked[:, 3:, :] == 0).all()  # âœ“ åé¢éƒ½æ˜¯0
```

### æµ‹è¯•2: å®Œæ•´åºåˆ—

```python
# å½“ keep_steps = 37 (æœ€å¤§å€¼)
X = torch.randn(4, 37, 14)
X_masked, keep_steps, time_ratio = temporal_masking_augmentation(
    X, min_ratio=1.0, max_ratio=1.0
)

assert keep_steps == 37  # âœ“ ä¿ç•™å…¨éƒ¨
assert torch.allclose(X_masked, X)  # âœ“ æ•°æ®ä¸å˜
assert time_ratio == 1.0  # âœ“ æ—¶é—´æ¯”ä¾‹=1
```

### æµ‹è¯•3: æŸå¤±æƒé‡

```python
# æ—©æœŸvsåæœŸæŸå¤±æƒé‡
criterion = CombinedEarlyLoss(time_weight_factor=2.0)

logits = torch.randn(32, 4)
targets = torch.randint(0, 4, (32,))

# æ—©æœŸï¼ˆ20%æ—¶é—´ï¼‰
loss_early, _ = criterion(logits, targets, time_ratio=0.2)
# å†…éƒ¨: weight = 1 + 2.0 * (1-0.2) = 2.6

# åæœŸï¼ˆ100%æ—¶é—´ï¼‰
loss_late, _ = criterion(logits, targets, time_ratio=1.0)
# å†…éƒ¨: weight = 1 + 2.0 * (1-1.0) = 1.0

# éªŒè¯
assert loss_early > loss_late  # âœ“ æ—©æœŸæŸå¤±æ›´å¤§
ratio = loss_early / loss_late
assert 2.0 < ratio < 3.0  # âœ“ æ¯”ä¾‹åœ¨åˆç†èŒƒå›´
```

---

## ğŸ“Š æ•°æ®æµå®Œæ•´æ€§æ£€æŸ¥

### å®Œæ•´çš„ä¸€ä¸ªBatch

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä»DataLoaderè·å–                    â”‚
â”‚ X: [64, 37, 14]                     â”‚
â”‚ y: [64]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¯¾ç¨‹å­¦ä¹ è°ƒåº¦                        â”‚
â”‚ min_ratio=0.5, max_ratio=1.0        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ—¶é—´Masking                         â”‚
â”‚ keep_ratio=0.65 (éšæœº)              â”‚
â”‚ keep_steps=24                       â”‚
â”‚ X_masked: [64, 37, 14]              â”‚
â”‚   - [:, :24, :] = real              â”‚
â”‚   - [:, 24:, :] = 0                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨¡å‹Forward                         â”‚
â”‚ logits = model(X_masked)            â”‚
â”‚ logits: [64, 4]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æŸå¤±è®¡ç®—                            â”‚
â”‚ loss = criterion(logits, y, 0.65)   â”‚
â”‚ time_weight = 1 + 2*(1-0.65) = 1.7  â”‚
â”‚ loss = focal_loss * 1.7             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åå‘ä¼ æ’­                            â”‚
â”‚ loss.backward()                     â”‚
â”‚ optimizer.step()                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ“ æ¯ä¸€æ­¥çš„tensorå½¢çŠ¶éƒ½æ­£ç¡®
âœ“ æ¢¯åº¦æµåŠ¨è·¯å¾„æ¸…æ™°
âœ“ æ²¡æœ‰ç»´åº¦ä¸åŒ¹é…
```

---

## âš ï¸ å·²çŸ¥é™åˆ¶

### 1. ä¸æ”¯æŒåŒæ¨¡æ€è®­ç»ƒ

**åŸå› **:
- åŒæ¨¡æ€éœ€è¦åŒæ—¶å¤„ç†è§†è§‰å’Œè¯­è¨€ç‰¹å¾
- éœ€è¦å®ç° `forward_with_features()` æ–¹æ³•
- cached_imagesä¸maskingçš„é…åˆéœ€è¦ç‰¹æ®Šå¤„ç†

**è§£å†³æ–¹æ¡ˆ**:
- å…ˆéªŒè¯language_onlyæœ‰æ•ˆæ€§
- åç»­æ‰©å±•åˆ°åŒæ¨¡æ€

### 2. cached_imagesæš‚æœªä½¿ç”¨

**åŸå› **:
- é¿å…ä¸æ—¶é—´maskingçš„ç»´åº¦ä¸åŒ¹é…
- ç®€åŒ–åˆç‰ˆå®ç°

**å½±å“**:
- è®­ç»ƒé€Ÿåº¦å¯èƒ½ç¨æ…¢ï¼ˆéœ€è¦å®æ—¶ç”Ÿæˆå›¾åƒï¼‰
- ä½†é€»è¾‘æ›´æ¸…æ™°ï¼Œæ›´æ˜“è°ƒè¯•

**ä¼˜åŒ–æ–¹å‘**:
- å®ç°åŠ¨æ€å›¾åƒæˆªæ–­
- æˆ–è€…è®­ç»ƒæ—¶ä¸ç”¨å›¾åƒï¼Œåªåœ¨æµ‹è¯•æ—¶ç”¨

### 3. å†…å­˜å ç”¨

**é—®é¢˜**:
- è™½ç„¶ä¸ç”¨cached_imagesï¼Œä½†ä»éœ€è¦åŠ¨æ€ç”Ÿæˆ
- `VisualPreprocessor` åœ¨forwardæ—¶è¿è¡Œ

**ä¼˜åŒ–**:
```python
# å¯é€‰ï¼šç¦ç”¨è§†è§‰æ¨¡å—
model.visual_module = None  # å®Œå…¨ä¸ç”¨è§†è§‰
# æˆ–è€…
model.use_visual = False
```

---

## ğŸ¯ æµ‹è¯•å»ºè®®

### å•å…ƒæµ‹è¯•

```python
def test_temporal_masking():
    X = torch.randn(8, 37, 14)
    X_masked, keep_steps, time_ratio = temporal_masking_augmentation(
        X, min_ratio=0.3, max_ratio=0.7
    )
    
    assert X_masked.shape == X.shape
    assert 11 <= keep_steps <= 26  # 0.3*37 â‰ˆ 11, 0.7*37 â‰ˆ 26
    assert 0.3 <= time_ratio <= 0.7
    print("âœ“ temporal_masking test passed")

def test_curriculum_scheduler():
    scheduler = CurriculumScheduler(
        total_epochs=100,
        warmup_epochs=20,
        min_ratio_start=0.7,
        min_ratio_end=0.2
    )
    
    # Warmupé˜¶æ®µ
    min_r, max_r = scheduler.get_time_range(10)
    assert min_r == 0.7
    assert max_r == 1.0
    
    # ä¸­æœŸ
    min_r, max_r = scheduler.get_time_range(60)
    assert 0.4 < min_r < 0.5
    
    # åæœŸ
    min_r, max_r = scheduler.get_time_range(100)
    assert min_r == 0.2
    
    print("âœ“ curriculum_scheduler test passed")

def test_loss_function():
    criterion = CombinedEarlyLoss(num_classes=4, time_weight_factor=2.0)
    
    logits = torch.randn(16, 4)
    targets = torch.randint(0, 4, (16,))
    
    loss_early, _ = criterion(logits, targets, time_ratio=0.3)
    loss_late, _ = criterion(logits, targets, time_ratio=0.9)
    
    assert loss_early.item() > loss_late.item()
    print("âœ“ loss_function test passed")

if __name__ == "__main__":
    test_temporal_masking()
    test_curriculum_scheduler()
    test_loss_function()
    print("\nâœ“ All tests passed!")
```

### é›†æˆæµ‹è¯•

```bash
# å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆ10ä¸ªepochï¼‰
python train_classification_improved.py \
    --epochs 10 \
    --batch_size 32

# æ£€æŸ¥è¾“å‡ºï¼š
# - æ˜¯å¦æ­£å¸¸æ”¶æ•›
# - æŸå¤±æ˜¯å¦ä¸‹é™
# - F1æ˜¯å¦æå‡
```

---

## ğŸ“ ä»£ç å®¡æŸ¥æ¸…å•

- [x] æŸå¤±å‡½æ•°è°ƒç”¨æ­£ç¡®
- [x] ç»´åº¦åŒ¹é…æ£€æŸ¥
- [x] è¾¹ç•Œæƒ…å†µå¤„ç†
- [x] æ¢¯åº¦æµåŠ¨æ­£ç¡®
- [x] å†…å­˜æ³„æ¼æ£€æŸ¥
- [x] è®¾å¤‡ä¸€è‡´æ€§ï¼ˆCPU/GPUï¼‰
- [x] æ•°å€¼ç¨³å®šæ€§
- [x] é”™è¯¯å¤„ç†
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ï¼ˆTODOï¼‰
- [ ] é›†æˆæµ‹è¯•ï¼ˆéœ€è¦å®é™…è¿è¡Œï¼‰

---

## ğŸš€ ä¸‹ä¸€æ­¥

1. **è¿è¡Œæµ‹è¯•**: 
   ```bash
   python train_classification_improved.py --epochs 10
   ```

2. **ç›‘æ§æŒ‡æ ‡**:
   - æŸå¤±ä¸‹é™æ›²çº¿
   - F1æå‡è¶‹åŠ¿
   - è¯¾ç¨‹å­¦ä¹ è¿›åº¦

3. **å¯¹æ¯”å®éªŒ**:
   - æ ‡å‡†æ–¹æ³• vs æ”¹è¿›æ–¹æ³•
   - éªŒè¯æå‡å¹…åº¦

4. **è°ƒä¼˜è¶…å‚æ•°**:
   - `time_weight_factor`: 1.5, 2.0, 2.5
   - `warmup_ratio`: 0.15, 0.2, 0.25
   - `min_ratio_end`: 0.15, 0.2, 0.25

---

## æ€»ç»“

âœ… **å·²ä¿®å¤çš„é—®é¢˜**:
1. æŸå¤±å‡½æ•°è°ƒç”¨é”™è¯¯
2. cached_imagesç»´åº¦ä¸åŒ¹é…
3. è¯­ä¹‰ä¸ä¸€è‡´

âœ… **éªŒè¯çš„é€»è¾‘**:
1. æ—¶é—´maskingæ­£ç¡®
2. æŸå¤±è®¡ç®—æ­£ç¡®
3. è¯¾ç¨‹å­¦ä¹ æ­£ç¡®
4. æ•°æ®æµå®Œæ•´

âœ… **ä»£ç è´¨é‡**:
- æ— linté”™è¯¯
- é€»è¾‘æ¸…æ™°
- æ³¨é‡Šå®Œæ•´
- æ˜“äºç»´æŠ¤

ğŸ¯ **ready for training!**


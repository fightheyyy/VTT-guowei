# 对比实验: 语言模态 vs 双模态产量预测

## 🎯 实验目标

对比纯语言模态和双模态（语言+视觉）在产量预测任务上的性能差距。

## 📊 对比内容

| 模型 | 架构 | 特点 |
|------|------|------|
| **语言模态only** | Transformer Encoder | 直接处理时间序列，端到端优化 |
| **双模态** | CLIP Vision + Transformer | 同时使用图像和时间序列特征 |

## 🚀 快速开始

### 方式1：使用批处理脚本（推荐）

```bash
run_comparison.bat
```

会有交互式菜单让你选择：
1. 快速测试（1-2小时，4个时间点）
2. 完整实验（4-6小时，6个时间点）
3. 自定义轮数

### 方式2：直接运行Python

```bash
# 快速测试
python experiments/yield_prediction/train_comparison.py --quick

# 完整实验
python experiments/yield_prediction/train_comparison.py

# 自定义轮数
python experiments/yield_prediction/train_comparison.py --epochs 100
```

## 📈 实验流程

```
For each 输入长度 (60天, 120天, 180天, ...):
    ↓
1. 训练语言模态模型
    - 创建 LanguageOnlyYieldPredictor
    - 训练N轮
    - 评估性能
    ↓
2. 训练双模态模型
    - 创建 SimpleYieldPredictor (use_vision=True)
    - 训练N轮
    - 评估性能
    ↓
3. 对比性能
    - 计算RMSE、MAE、R²、MAPE
    - 记录差异
    ↓
4. 保存结果和模型
```

## 📁 输出结果

### 1. 对比JSON

`experiments/yield_prediction/comparison/results/comparison.json`

```json
{
  "timestamp": "20240106_143022",
  "config": {
    "input_steps_list": [6, 12, 18, 24, 30, 36],
    "epochs": 50,
    "device": "cuda"
  },
  "language_only": {
    "6": {
      "days": 60,
      "rmse": 0.3652,
      "mae": 0.2138,
      "r2": 0.0141,
      "mape": 3.2
    },
    ...
  },
  "dual_modal": {
    "6": {
      "days": 60,
      "rmse": 0.3806,
      "mae": 0.2250,
      "r2": -0.0854,
      "mape": 3.5
    },
    ...
  }
}
```

### 2. 对比图表

`experiments/yield_prediction/comparison/results/comparison.png`

包含4个子图：
- **左上**: RMSE对比（越低越好）
- **右上**: R²对比（越高越好）
- **左下**: MAE对比（越低越好）
- **右下**: RMSE差异（负值=语言更好，正值=双模态更好）

### 3. 训练曲线

```bash
tensorboard --logdir=experiments/yield_prediction/comparison/logs
```

可查看：
- `language_steps6/`: 语言模态（60天输入）
- `dual_steps6/`: 双模态（60天输入）
- ... 其他时间点

### 4. 保存的模型

```
experiments/yield_prediction/comparison/checkpoints/
├── language_steps6.pth
├── dual_steps6.pth
├── language_steps12.pth
├── dual_steps12.pth
└── ...
```

## 📊 控制台输出示例

```
================================================================================
对比实验: 语言模态 vs 双模态产量预测
================================================================================

配置:
  设备: cuda
  训练数据: 2019-2021年（3年）
  测试数据: 2022年
  测试点: [6, 12, 18, 24, 30, 36]
  训练轮数: 50

================================================================================
测试: 6步 = 60天
================================================================================

加载数据（输入=6步=60天）
  数据集: 1499 样本, 6步(60天)
  数据集: 499 样本, 6步(60天)

[1/2] 训练语言模态模型...
  [Language] Epoch 10: Val=0.9711, RMSE=0.3628, R²=0.0141 ✓
  [Language] Epoch 20: Val=0.9503, RMSE=0.3588, R²=0.0355 ✓
  [Language] 早停于Epoch 27

  语言模态结果:
    RMSE: 0.3588
    MAE:  0.1974
    R²:   0.0355
    MAPE: 2.9%

[2/2] 训练双模态模型...
  [Dual] Epoch 10: Val=0.9779, RMSE=0.3644, R²=0.0051 ✓
  [Dual] Epoch 20: Val=0.9480, RMSE=0.3581, R²=0.0393 ✓
  [Dual] 早停于Epoch 35

  双模态结果:
    RMSE: 0.3718
    MAE:  0.1935
    R²:   -0.0355
    MAPE: 2.8%

  对比 (语言 vs 双模态):
    RMSE差异: -0.0130 (语言更好)
    R²差异:   +0.0710 (语言更好)

...

================================================================================
详细对比表格
================================================================================
天数     语言RMSE     双模态RMSE    差异        语言R²     双模态R²
--------------------------------------------------------------------------------
60       0.3588       0.3718       -0.0130 (语言更好)    0.0355     -0.0355
120      0.3684       0.3806       -0.0122 (语言更好)    -0.0168    -0.0854
180      0.3742       0.3907       -0.0165 (语言更好)    -0.0490    -0.1433
240      0.3651       0.3684       -0.0033 (语言更好)    0.0015     -0.0168
300      0.3718       0.3805       -0.0087 (语言更好)    -0.0355    -0.0796
360      0.3613       0.3614       -0.0001 (语言更好)    0.0222     0.0213
================================================================================
```

## 🔍 关键观察点

### 1. RMSE对比
- **预期**: 语言模态应该普遍低于双模态
- **原因**: 端到端优化，无额外噪声

### 2. R²对比
- **预期**: 语言模态应该更高（更接近0或正值）
- **原因**: 更好地捕捉产量变化

### 3. 随输入长度变化
- **观察**: 性能差距是否随输入长度变化
- **可能**: 在某些长度下双模态可能更好

### 4. 训练稳定性
- **观察**: 哪个模型收敛更快、更稳定

## 📝 实验参数

| 参数 | 值 |
|------|-----|
| **测试输入长度** | 60, 120, 180, 240, 300, 360天 |
| **训练轮数** | 50 (默认) |
| **学习率** | 1e-4 |
| **Batch Size** | 32 |
| **早停patience** | 15轮 |
| **模型维度** | 256 |
| **优化器** | AdamW (weight_decay=1e-5) |

## 💡 预期结果

基于之前的初步实验：

1. **语言模态优势**:
   - RMSE更低（约-0.01到-0.02）
   - R²更高（约+0.05到+0.10）
   - 训练更快、更稳定

2. **双模态挑战**:
   - 视觉特征可能引入噪声
   - 对比学习损失可能干扰主任务
   - 需要更多轮数才能收敛

3. **可能的例外**:
   - 在某些特定长度（如360天）双模态可能表现更好
   - 全年数据时，图像特征可能更有价值

## 🛠️ 故障排除

### GPU内存不足

```bash
# 减小batch size（修改train_comparison.py第190行）
batch_size=16  # 或更小
```

### 网络超时

脚本已设置离线模式，确保CLIP模型已缓存：
```python
os.environ['TRANSFORMERS_OFFLINE'] = '1'
```

### 数据文件找不到

确保数据文件在正确位置：
```
data/
├── 2019产量数据.csv
├── 2020产量数据.csv
├── 2021产量数据.csv
└── 2022产量数据.csv
```

## 📚 相关文档

- `RUN_YIELD_PREDICTION.md`: 单独运行语言模态实验
- `ALGORITHM_GUIDE.md`: 算法原理说明
- `ARCHITECTURE_ANALYSIS.md`: 架构分析

## 🎓 结论建议

实验完成后，根据结果判断：

1. **如果语言模态明显更好**：
   - 继续使用语言模态
   - 优化超参数进一步提升性能
   
2. **如果双模态更好**：
   - 分析为什么双模态在这个任务上有效
   - 可能需要调整对比学习权重
   
3. **如果性能相近**：
   - 考虑计算成本，选择更简单的模型
   - 或在不同场景下使用不同模型

---

**开始实验**: `run_comparison.bat` 或 `python experiments/yield_prediction/train_comparison.py --quick` 🚀


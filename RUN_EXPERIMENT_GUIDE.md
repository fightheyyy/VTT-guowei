# 运行消融实验指南

## 三种运行方式

### 方式1: 自动化完整实验（推荐）⭐

**使用 Python 脚本（推荐）**：
```bash
python run_ablation_experiment.py
```

**或使用批处理文件**：
```bash
run_ablation_experiment.bat
```

**功能**：
- ✅ 自动依次训练双模态 → 语言模态 → 对比结果
- ✅ 保存详细日志
- ✅ 实时显示训练进度
- ✅ 自动错误处理
- ✅ 生成对比报告

**预计时间**：
- 双模态训练: 8-10 小时
- 语言模态训练: 2-3 小时
- 对比分析: < 5 分钟
- **总计**: 约 10-13 小时

**输出**：
```
checkpoints/
├── stage1_timeseries_best.pth       (双模态模型)
└── stage1_language_only_best.pth    (语言模态模型)

experiment_logs/
├── step1_both_modal_TIMESTAMP.log
├── step2_language_only_TIMESTAMP.log
└── step3_comparison_TIMESTAMP.log

comparison_results.json                (对比结果)
```

---

### 方式2: 快速测试（只运行语言模态）⚡

如果想快速看效果，可以只训练语言模态版本：

```bash
run_language_only_quick.bat
```

或：

```bash
python train_language_only.py
```

**优点**：
- ⚡ 只需 2-3 小时
- ⚡ 快速验证代码是否正常
- ⚡ 可以先看语言模态的效果

**输出**：
```
checkpoints/
└── stage1_language_only_best.pth

logs/
└── stage1_language_only/
```

**注意**：无法对比，因为没有双模态的结果。

---

### 方式3: 手动逐步运行（最灵活）

如果需要更多控制，可以手动一步步执行：

```bash
# 步骤1: 训练双模态（8-10小时）
python train_multiyear_mirror.py

# 步骤2: 训练语言模态（2-3小时）
python train_language_only.py

# 步骤3: 对比结果
python compare_results.py
```

**适合场景**：
- 想在两次训练之间检查结果
- 只想运行某一个模型
- 需要调整参数后重新训练

---

## 详细说明

### 运行前准备

1. **确认环境**：
```bash
python --version          # 应该是 3.8+
python -c "import torch; print(torch.__version__)"
python -c "import torch; print(torch.cuda.is_available())"
```

2. **检查数据**：
```
extract2019_20251010_165007.csv  ✓
extract2020_20251010_165007.csv  ✓
extract2021_20251010_165007.csv  ✓
extract2022_20251010_165007.csv  ✓
```

3. **检查显存**（1080 Ti）：
```bash
nvidia-smi
# 确保有至少 6GB 可用显存
```

---

### 实时监控

#### 终端输出
训练过程会实时显示：
```
Epoch 1/100: 100%|██████| 187/187 [05:16<00:00, 1.69s/it, loss=0.785]

Epoch 1/100:
  Train Loss: 0.939586
  Val Loss:   0.753231
  保存最佳模型
```

#### TensorBoard（推荐）
在另一个终端运行：
```bash
tensorboard --logdir=logs
```
访问 `http://localhost:6006` 查看训练曲线

#### 查看日志文件
如果使用自动化脚本，日志保存在：
```
experiment_logs/step1_both_modal_TIMESTAMP.log
experiment_logs/step2_language_only_TIMESTAMP.log
```

---

### 中途暂停与恢复

#### 如何暂停
- 按 `Ctrl+C` 可以安全停止训练
- 已保存的 checkpoint 不会丢失

#### 已保存的 Checkpoint
每10个epoch会自动保存：
```
checkpoints/
├── stage1_epoch_10.pth
├── stage1_epoch_20.pth
└── ...
```

#### 如何恢复（需手动修改代码）
修改训练脚本，添加：
```python
# 在创建模型后
if os.path.exists('checkpoints/stage1_epoch_20.pth'):
    model.load_state_dict(torch.load('checkpoints/stage1_epoch_20.pth'))
    print("从 epoch 20 继续训练")
```

---

### 预期结果

#### 双模态训练过程
```
Epoch 1/100:
  Train Loss: 0.939586 (Gen: 0.538376, Align: 4.012097)
  Val Loss:   0.753231
  
Epoch 50/100:
  Train Loss: 0.297448 (Gen: 0.177863, Align: 1.195850)
  Val Loss:   0.532061
```

**关键指标**：
- Gen Loss: 0.538 → 0.178 (RMSE: 0.73 → 0.42)
- Align Loss: 4.01 → 1.20
- Val Loss: 0.753 → 0.532

#### 语言模态训练过程
```
Epoch 1/100:
  Train Loss: 0.542138 (RMSE: 0.7363)
  Val Loss:   0.518245 (RMSE: 0.7199)
  
Epoch 100/100:
  Train Loss: 0.180234 (RMSE: 0.4246)
  Val Loss:   0.525789 (RMSE: 0.7251)
```

**关键指标**：
- Train Loss: 0.542 → 0.180 (RMSE: 0.74 → 0.42)
- Val Loss: 0.518 → 0.526 (RMSE: 0.72 → 0.73)

#### 对比结果示例
```
阶段1（时间序列补全）:
  指标              双模态          语言模态        差异
  ────────────────────────────────────────────────
  RMSE:            0.4220       0.4301       +1.9%
  参数量:          25,648,128   18,432,000   -28.1%
  训练时间:        8.5小时      2.5小时      快3.4倍

  性能保留率: 98.1%
  结论: ⭐ 语言模态性能相当，建议去掉视觉模态
```

---

## 常见问题

### Q1: 训练太慢，能加速吗？
**A**: 
- 双模态很慢是正常的（图像生成开销大）
- 可以先跑语言模态版本（快3-5倍）
- 如果语言模态效果好，就不用跑双模态了

### Q2: 显存不足怎么办？
**A**: 
```python
# 修改 batch_size
batch_size=8  →  batch_size=4
```

### Q3: 能否只对比已有的模型？
**A**: 
可以。如果已经有训练好的模型：
```bash
python compare_results.py
```
脚本会自动查找：
- `checkpoints/stage1_timeseries_best.pth`
- `checkpoints/stage1_language_only_best.pth`

### Q4: 中途停止了，如何继续？
**A**: 
最简单的方法是重新运行（模型会自动覆盖）。
如果想从checkpoint继续，需要手动修改训练脚本加载checkpoint。

### Q5: 为什么语言模态也这么慢？
**A**: 
语言模态主要时间在：
- BERT 编码（预训练模型，较重）
- Transformer 计算

如果还嫌慢，可以：
- 减小 `d_model`: 256 → 128
- 减小 `epochs`: 100 → 50

### Q6: 如何知道训练是否正常？
**A**: 
观察：
1. Loss 应该逐渐下降
2. Val Loss 应该小于 1.0
3. 双模态的 Align Loss 应该从 4.0 降到 1.0 左右
4. 不应该出现 NaN 或 Inf

### Q7: 结果不理想怎么办？
**A**: 
检查：
1. 数据是否正确加载（看日志输出）
2. 是否有数据归一化
3. 学习率是否合适
4. 是否需要更多 epochs

---

## 建议的工作流程

### 方案A：快速验证（1天）
1. 先运行语言模态版本（2-3小时）
2. 查看结果，如果效果好就用这个
3. 不需要跑双模态了

### 方案B：完整对比（2天）
1. 晚上运行双模态（过夜，8-10小时）
2. 第二天运行语言模态（2-3小时）
3. 对比结果，得出结论

### 方案C：分时段运行
1. 周五晚上：启动双模态训练
2. 周六早上：检查结果
3. 周六下午：运行语言模态训练
4. 周六晚上：对比结果

---

## 输出文件说明

### 模型文件
- `stage1_timeseries_best.pth`: 双模态最佳模型（约100-200MB）
- `stage1_language_only_best.pth`: 语言模态最佳模型（约70-100MB）

### 日志文件
- `logs/stage1/`: 双模态训练 TensorBoard 日志
- `logs/stage1_language_only/`: 语言模态训练 TensorBoard 日志
- `experiment_logs/`: 详细文本日志

### 结果文件
- `comparison_results.json`: JSON格式的对比数据
- 终端输出: 格式化的对比表格

---

## 小贴士

1. **使用 tmux/screen**（Linux）或在后台运行，避免终端断开
2. **监控GPU使用率**：`nvidia-smi` 或 `watch -n 1 nvidia-smi`
3. **定期查看日志**，确保训练正常
4. **备份模型文件**，训练完成后及时保存
5. **记录实验参数**，方便后续对比

---

## 预期输出示例

运行 `python run_ablation_experiment.py` 后：

```
======================================================================
消融实验：对比双模态 vs 语言模态
======================================================================

实验开始时间: 2025-10-23 20:00:00
时间戳: 20251023_200000
日志目录: experiment_logs/
✓ 环境检查通过

----------------------------------------------------------------------
[1/3] 训练双模态版本
----------------------------------------------------------------------
预计时间: 8-10 小时
模型: TimesCLIP (视觉 + 语言 + 对比学习)
开始时间: 2025-10-23 20:00:15
[训练过程...]
完成时间: 2025-10-24 04:30:42
耗时: 8小时 30分钟 27秒
✓ 成功完成

----------------------------------------------------------------------
[2/3] 训练语言模态版本
----------------------------------------------------------------------
预计时间: 2-3 小时
模型: TimesCLIPLanguageOnly (仅语言模态)
开始时间: 2025-10-24 04:30:50
[训练过程...]
完成时间: 2025-10-24 07:15:23
耗时: 2小时 44分钟 33秒
✓ 成功完成

----------------------------------------------------------------------
[3/3] 对比两个版本的性能
----------------------------------------------------------------------
[对比结果...]

======================================================================
✓ 实验全部完成！
======================================================================
实验结束时间: 2025-10-24 07:20:15
总耗时: 11小时 20分钟

结果文件:
  - checkpoints/stage1_timeseries_best.pth (双模态)
  - checkpoints/stage1_language_only_best.pth (语言模态)
  - comparison_results.json (对比结果)

对比结果摘要:
======================================================================

阶段1 - 时间序列补全:
  双模态 RMSE:    0.4220
  语言模态 RMSE:  0.4301
  差异:           +1.9%
  性能保留率:     98.1%

  结论: ⭐ 语言模态性能相当（差异<5%），建议去掉视觉模态
```

---

祝实验顺利！如有问题请查看日志文件。

